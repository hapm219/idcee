import time
from load_model import load_llm

def main():
    llm = load_llm()
    print("ü§ñ IDCee s·∫µn s√†ng! G√µ 'exit' ƒë·ªÉ tho√°t.\n")

    while True:
        user_input = input("üßë You: ").strip()
        if user_input.lower() in ["exit", "quit"]:
            break

        # Prompt template ƒë·ªãnh h∆∞·ªõng r√µ r√†ng
        prompt = f"""B·∫°n l√† tr·ª£ l√Ω AI t√™n IDCee. H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, ch√≠nh x√°c, d·ªÖ hi·ªÉu.
N·∫øu c√¢u tr·∫£ l·ªùi c√≥ nhi·ªÅu √Ω, h√£y tr√¨nh b√†y b·∫±ng danh s√°ch g·∫°ch ƒë·∫ßu d√≤ng.

C√¢u h·ªèi: {user_input}
Tr·∫£ l·ªùi:"""

        start = time.time()
        try:
            response = llm(prompt, max_new_tokens=1024)
            elapsed = time.time() - start

            if not response or str(response).strip() == "":
                print("ü§ñ IDCee: (Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi)")
            else:
                print(f"ü§ñ IDCee: {response.strip()}")

            print(f"‚è±Ô∏è Th·ªùi gian ph·∫£n h·ªìi: {elapsed:.2f} gi√¢y\n")

        except Exception as e:
            print(f"‚ùå L·ªói infer: {e}")
            continue

if __name__ == "__main__":
    main()
